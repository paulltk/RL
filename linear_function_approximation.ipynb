{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "rmbiwRRFny9_",
    "outputId": "9d87bd6d-2daa-4845-e3e6-aedecfdfeb68"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/gdrive\")\n",
    "\n",
    "import csv\n",
    "import time\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6ej9xqsny-l"
   },
   "source": [
    "#### Normalize state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XZsAht1Tny-o"
   },
   "outputs": [],
   "source": [
    "# Returns the state scaled between 0 and 1\n",
    "def normalize_state(_s):\n",
    "    _y = np.zeros(len(_s))\n",
    "    for _i in range(len(_s)):\n",
    "        _y[_i] = (_s[_i] - xbar[0, _i]) / (xbar[1, _i] - xbar[0, _i])\n",
    "    return _y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYg59vCpny-0"
   },
   "source": [
    "#### Basis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "id": "btQb3ZnKny-3",
    "outputId": "98256c20-0b74-4f25-af4f-8844e621c674",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class BasisFunction(object): \n",
    "    def __init__(self, discrt, dim, num_actions): \n",
    "        \n",
    "        self.dim = dim\n",
    "        print(\"dim\", self.dim)\n",
    "        self.num_actions = num_actions\n",
    "        print(\"num_actions\", )\n",
    "        self.num_rbf = discrt * np.ones(self.dim).astype(int)\n",
    "        self.width = 1. / (self.num_rbf - 1.)\n",
    "\n",
    "        self.rbf_sigma = self.width[0] / 2.\n",
    "        \n",
    "        self.num_ind = np.prod(self.num_rbf)\n",
    "        self.rbf_den = 2 * self.rbf_sigma ** 2\n",
    "        \n",
    "        c = np.zeros((self.num_ind, dim))\n",
    "        for i in range(self.num_ind):\n",
    "            if i == 0:\n",
    "                pad_num = self.dim\n",
    "            else:\n",
    "                pad_num = self.dim - int(np.log(i) / np.log(discrt)) - 1\n",
    "            ind = np.base_repr(i, base=discrt, padding=pad_num)\n",
    "            ind = np.asarray([float(j) for j in list(ind)])\n",
    "            c[i, :] = self.width * ind\n",
    "        \n",
    "        print(\"c.shape\", c.shape)\n",
    "        print(\"c\", c)\n",
    "        \n",
    "        self.c = c\n",
    "\n",
    "    def get_activations(self, _state):\n",
    "        \"\"\"function phi retrieves a state, and gives feature \n",
    "        vector (called activations) as output.\"\"\"\n",
    "        _phi = np.zeros(self.num_ind)\n",
    "        \n",
    "        for _k in range(self.num_ind):\n",
    "            _phi[_k] = np.exp(-np.linalg.norm(_state - self.c[_k, :]) ** 2 / \n",
    "                              self.rbf_den)\n",
    "        \n",
    "        return _phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2YVCWPTHny_T"
   },
   "source": [
    "#### Greedy policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KM8CdUO4ny_W"
   },
   "outputs": [],
   "source": [
    "# Returns an action following an epsilon-greedy policy\n",
    "def epsilon_greedy(_epsilon, _vals):\n",
    "    _rand = np.random.random()\n",
    "    if _rand < 1. - _epsilon:\n",
    "        _action = _vals.argmax()\n",
    "    else:\n",
    "        _action = env.action_space.sample()\n",
    "    return int(_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjTdqz2rny_e"
   },
   "source": [
    "#### Retrieve Q-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GLquVi89ny_f"
   },
   "outputs": [],
   "source": [
    "# Returns the value of each action at some state\n",
    "def action_values(_activations, _theta):\n",
    "    _val = np.dot(_theta.T, _activations)\n",
    "    return _val\n",
    "\n",
    "\n",
    "# Returns the value of an action at some state\n",
    "def action_value(_activations, _action, _theta):\n",
    "    _val = np.dot(_theta[:, _action], _activations)\n",
    "    return _val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_rRcZzVny_k"
   },
   "source": [
    "#### Gradient functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zbvg0OaZny_l"
   },
   "outputs": [],
   "source": [
    "def semi_gradient(theta, activations, action, reward, done, Q, Q_new, num_ind, gamma, alpha):\n",
    "    if done:\n",
    "        target = reward - Q\n",
    "    else:\n",
    "        target = reward + Q_new - Q\n",
    "\n",
    "    for k in range(num_ind):\n",
    "        theta[k, action] += alpha * target * activations[k]\n",
    "        \n",
    "    return theta\n",
    "\n",
    "def full_gradient(theta, activations, new_activations, action, reward, done, Q, Q_new, num_ind, gamma, alpha):\n",
    "    if done:\n",
    "        target = reward - Q\n",
    "    else:\n",
    "        target = reward + Q_new - Q\n",
    "\n",
    "    for k in range(num_ind):\n",
    "        theta[k, action] -= alpha * target * (gamma * new_activations[k] - activations[k])\n",
    "        \n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c7QG_uLpny_r"
   },
   "source": [
    "#### Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8n0ue01yny_r",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(env, gradient='semi', normalize=True, std=0, alpha=0.01, gamma=1, discrt=4, num_episodes=2000, num_timesteps=400, epsilon=0.1, print_every=10, seed=0):\n",
    "\n",
    "    filename = f\"environment {environment}_{gradient} gradient_std {std}_alpha {alpha}_discrt {discrt}_gamma {gamma} _steps {num_timesteps}_seed {seed}_time {int(time.time())}_epsilon {epsilon}\"\n",
    "    print(filename)\n",
    "\n",
    "    num_actions = env.action_space.n\n",
    "    state_dim = env.observation_space.high.size\n",
    "\n",
    "    bf = BasisFunction(discrt, state_dim, num_actions)\n",
    "    # rbf_feature = RBFSampler(gamma=1, random_state=1)\n",
    "\n",
    "    ep_length = []\n",
    "    ten_eps = []\n",
    "\n",
    "    theta = np.random.normal(0, std, size=(bf.num_ind, num_actions))\n",
    "    # theta = np.random.normal(0, std, size=(100, num_actions))\n",
    "    \n",
    "    # SARSA loop\n",
    "    for ep in range(num_episodes):\n",
    "        \n",
    "        state = env.reset()\n",
    "        \n",
    "        if normalize:\n",
    "            state = normalize_state(state)\n",
    "        \n",
    "        activations = bf.get_activations(state)\n",
    "        # print(\"old\", activations.shape)\n",
    "        # activations = rbf_feature.fit_transform(state.reshape(1, -1))[0]\n",
    "        # print(\"new\", activations.shape)\n",
    "\n",
    "        eps = epsilon - (epsilon / num_episodes * ep) \n",
    "\n",
    "        vals = action_values(activations, theta)\n",
    "        action = epsilon_greedy(eps, vals)\n",
    "\n",
    "        # Each episode\n",
    "        for t in range(num_timesteps):\n",
    "\n",
    "            new_state, reward, done, info = env.step(action)\n",
    "\n",
    "            if t == (num_timesteps - 1):\n",
    "                done = True\n",
    "\n",
    "            if normalize:\n",
    "                new_state = normalize_state(new_state)\n",
    "            \n",
    "            new_activations = bf.get_activations(new_state)\n",
    "            # new_activations = rbf_feature.fit_transform(new_state.reshape(1, -1))[0]\n",
    "        \n",
    "            new_vals = action_values(new_activations, theta)\n",
    "            new_action = epsilon_greedy(eps, new_vals)\n",
    "            \n",
    "            Q = action_value(activations, action, theta)\n",
    "            Q_new = action_value(new_activations, new_action, theta)\n",
    "\n",
    "            if gradient == 'semi':\n",
    "                theta = semi_gradient(theta, activations, \n",
    "                                      action, reward, done, Q, Q_new, \n",
    "                                      bf.num_ind, gamma, alpha)\n",
    "                # print(theta)\n",
    "            elif gradient == 'full':\n",
    "                theta = full_gradient(theta, activations, new_activations, \n",
    "                                      action, reward, done, Q, Q_new, \n",
    "                                      bf.num_ind, gamma, alpha)\n",
    "            else:   \n",
    "                raise ValueError('variable \"gradient\" must be in [\"semi\", \"full\"].')\n",
    "\n",
    "            state = new_state.copy()\n",
    "            activations = new_activations.copy()\n",
    "            action = new_action\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        ep_length.append(t)\n",
    "        ten_eps.append(t)\n",
    "\n",
    "        if (ep + 1) % print_every == 0: \n",
    "            avg_steps = sum(ten_eps) / len(ten_eps)\n",
    "            ten_eps = []\n",
    "            print(f\"episode {ep}: {avg_steps} steps\")\n",
    "    \n",
    "    with open(f'/content/gdrive/My Drive/RL/{filename}.csv', 'w') as f:   \n",
    "        write = csv.writer(f) \n",
    "        write.writerow(ep_length)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-L6PjGJO6DD1"
   },
   "source": [
    "#### Plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4zmDt0686GoB"
   },
   "outputs": [],
   "source": [
    "def plot_results(results):\n",
    "    for title, result in results.items(): \n",
    "        result = np.array(result)\n",
    "        x = list(range(0, result.shape[1]*gather, gather))\n",
    "\n",
    "        print(result.shape)\n",
    "        mu = result.mean(axis=0)\n",
    "        min_std = mu - result.std(axis=0)\n",
    "        max_std = mu + result.std(axis=0)\n",
    "\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.plot(x, mu)\n",
    "        plt.fill_between(x, max_std, min_std, alpha=0.5)\n",
    "        plt.xlabel(\"episodes\")\n",
    "        plt.ylabel(\"timesteps\")\n",
    "        print(title)\n",
    "        plt.title(title)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGaDaY3R5JHR"
   },
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "OtEtaYIuny-K",
    "outputId": "f460c637-78a3-4825-8157-4de48501e43d"
   },
   "outputs": [],
   "source": [
    "environment = \"MountainCar-v0\"\n",
    "# environment = \"CartPole-v1\"\n",
    "\n",
    "env = gym.make(environment).env\n",
    "# env = gym.make(environment)\n",
    "\n",
    "# nescesary to normalize the state \n",
    "num_actions = env.action_space.n\n",
    "state_dim = env.observation_space.high.size\n",
    "print(num_actions, state_dim)\n",
    "\n",
    "xbar = np.zeros((2, state_dim))\n",
    "xbar[0, :] = env.observation_space.low\n",
    "xbar[1, :] = env.observation_space.high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HruQzTT5ny_x",
    "outputId": "d7674b54-debe-46da-ddea-fe0fdfe3f04c"
   },
   "outputs": [],
   "source": [
    "std=0   \n",
    "alpha=0.005\n",
    "discrt=4\n",
    "gamma=1\n",
    "num_episodes=1000\n",
    "num_timesteps=400\n",
    "epsilon=0.1\n",
    "print_every=100\n",
    "\n",
    "for gradient in ['semi', 'full']: \n",
    "    for std in [.1]:\n",
    "        for seed in range(10): \n",
    "            env.seed(seed)\n",
    "            np.random.seed(seed)\n",
    "            random.seed(seed)\n",
    "            env.action_space.seed(seed)\n",
    "\n",
    "            train(env, gradient=gradient, std=std, alpha=alpha, gamma=gamma, discrt=discrt, \n",
    "                num_episodes=num_episodes, num_timesteps=num_timesteps, epsilon=epsilon, \n",
    "                print_every=print_every, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "tMLWtH4Yny_2",
    "outputId": "e8e719fe-f332-403d-9e1d-b978ff1b3dfc"
   },
   "outputs": [],
   "source": [
    "mypath = '/content/gdrive/My Drive/RL/'\n",
    "gather = 10\n",
    "substrings = [\"MountainCar-v0\"]\n",
    "\n",
    "results = defaultdict(list)\n",
    "files = [f for f in listdir(mypath) if isfile(join(mypath, f)) and all(substr in f for substr in substrings)]\n",
    "\n",
    "for file in files:\n",
    "    envrnmnt, gradient, std, alpha, discrt, gamma, steps, seed, timestamp, epsilon = file.split(\"_\")\n",
    "    \n",
    "    with open(f'{mypath}{file}') as f:\n",
    "        reader = csv.reader(f)\n",
    "        data = list(map(int, list(reader)[0]))\n",
    "    \n",
    "    data = list(np.mean(np.array(data).reshape(-1, gather), axis=1))\n",
    "\n",
    "    results[f\"{gradient} with {std}\"].append(data)\n",
    "        \n",
    "print(list(results.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Pf4qI7Vyny__",
    "outputId": "4a38946b-20ed-4e6f-efce-4ddc87e382b8"
   },
   "outputs": [],
   "source": [
    "plot_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get mean episode length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1vlcq7-PTAr3",
    "outputId": "209864b4-858f-4a9d-b091-48261b6e2dc7"
   },
   "outputs": [],
   "source": [
    "for title, result in results.items(): \n",
    "    print(title)\n",
    "    result = np.array(result)\n",
    "    \n",
    "    print(result.shape)\n",
    "    mu = result.mean(axis=0)[200:]\n",
    "    print(mu.mean())\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "radial basis function.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

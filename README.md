# Date
23-10-2020

# Authors
Daan Le (daan_le@hotmail.com) <br>
David Wessels (davidwessels15@gmail.com) <br>
David Knigge (davidknigge@live.nl) <br>
Paul ten Kaate (paultenkaate@outlook.com) <br>

# Files 
This github repo is created during a reproducibility mini project for the UvA master course Reinforcement Learning, taught by Herke van Hooff. This project looks into the differences between the full gradient and semi gradient function approximation methods with reinforcement learning. We conducted experiments for two different models, linear function approximation and Deep Q function approximation. These two models are tested against two different environmetns, cartpole and mountain car. Within this repository there are two different notebooks available for the two different models, where we can find experiments regarding both environments. The resulting paper is added in the repository to show our results and conclusions.<br>
The Linear function approximation implementation can be found in *linear_function_approximation.ipynb*. The Deep Q-network implementation can be found in *DQN_function_approximation.ipynb*. The final paper can be found in *reproducibility_project.pdf*. The result directory is currently not filled, but already made such that the DQN notebook runs without any errors.
